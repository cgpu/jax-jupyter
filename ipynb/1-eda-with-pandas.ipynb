{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) of the _iris_ dataset in python \n",
    "\n",
    " __email__: christina@lifebit.ai\n",
    " \n",
    "(or create a new issue in the workshop's github repo [here](https://github.com/lifebit-ai/jax-jupyter/issues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, let's set a selection of fav colors, to use in our plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_palette = ['sandybrown',\n",
    "              'palevioletred',\n",
    "              'cornflowerblue',\n",
    "              'gold',\n",
    "              'tomato',\n",
    "              'greenyellow',\n",
    "              'palevioletred',\n",
    "              'darkcyan']\n",
    "\n",
    "# this is my palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How-to here:  http://bit.ly/jupy_display_image\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://miro.medium.com/max/735/1*g3NVaR0mjWmzL3widxXO6w.png\",  width=600, height=600 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's add a bit of interactivity:\n",
    "\n",
    "This bit allows for light blue highlighting when hovering over tables and stuff. <br>\n",
    "\n",
    "You can check this out in a bit, when we will be printing the __`head()`__ of a panDataFrame :).\n",
    "\n",
    "Just hover your cursor above rows;<br>\n",
    "alt rows are highlighted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit just allows for highlighting when hovering over tables and stuff basically\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take care of dependencies: \n",
    "\n",
    "Make sure you have already installed the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing dependencies:    \n",
    "from sklearn import datasets # we will use iris dataset for this exercise \n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#1.11\n",
    "\n",
    "# Ignore warnings \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select style to use for your upcoming plots\n",
    "(I will choose `ggplot` ❤️)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "#To see all available style run the following command:\n",
    "plt.style.available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we're ready to start!\n",
    "\n",
    "Let's choose our favorite dataset, `iris` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accesing sklearn's datasets and Assigning dataset to the variable `iris`:\n",
    "\n",
    "from sklearn import datasets \n",
    "iris = datasets.load_iris()\n",
    "\n",
    "## EXPLORING OBJECT TYPE of iris dataset | w8_4_it, it's a new one;\n",
    "\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm.. Well, thanks a <b>Bunch</b>!  :p\n",
    "\n",
    "But what a <b>Bunch</b> _really_ is?\n",
    "\n",
    "According to sklearn documentation: http://bit.ly/sklearn_dataset_iris\n",
    "\n",
    "__BUNCH__:<br>\n",
    "Dictionary-like object; the interesting attributes are: <br>\n",
    "<b>‘data’</b>,          the data to learn, <br>\n",
    "<b>‘target’</b>,        the classification labels, <br>\n",
    "<b>‘target_names’</b>,  the meaning of the labels, <br>\n",
    "<b>‘feature_names’</b>, the meaning of the features, and <br>\n",
    "<b>‘DESCR’</b>,         the full description of the dataset. <br>\n",
    "\n",
    "For more info about what a Bunch object check here: http://bit.ly/pyBunch <br>\n",
    "or alt check your var explorer if working with Spyder #_ignore if you're a Command-Line Text Editor  snob :p _\n",
    "\n",
    "Well, since a __`Bunch`__ is a  __\"Dictionary-like object\"__, let's check its __`.keys()`__ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check the DESCR:\n",
    "\n",
    "One of the __`.keys()`__ is named `DESCR`, no wild guesses needed to figure out what this's about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plenty of info for the iris dataset. Now let's move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a table ready for writing to .csv from the sklearn Bunch object:\n",
    "\n",
    "First we will combine the `data` object, that contains the numerical variables \n",
    "- `sepal length (cm)`\n",
    "- `sepal width (cm)`  \n",
    "- `petal length (cm)` \n",
    "- `petal width (cm)` \n",
    "\n",
    "with the recoded species dummy variable named \n",
    "- `target`. \n",
    "\n",
    "The `iris['data']` and the `iris['target']` object are both np arrays, hence we will use  `np.c_` (`numpy concatenate`) to add the two numpy arrays together, before adding it to the Pandas Dataframe. The column names called `feature_names` are stored in a list so we can use the `+` operator to add a new element, the name of the last column (`target`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris['data'])\n",
    "type(iris['target'])\n",
    "type(iris['feature_names'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing files from Pandas Dataframes\n",
    "\n",
    "The dataframe looks great! Time to save it in a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading files from `.csv` into Pandas Dataframe\n",
    "\n",
    "We can now read back our save `.csv` file using the pandas method `read_csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's explore \n",
    " ### A. The object types that hold our data,  using `type()` built-in function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris['data']), type(iris['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Their dimension using `(iris['data'].shape)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.34\n",
    "#Our measurements for each feature live here:\n",
    "\n",
    "iris['data'].shape, #[o]: (150,4) aka # N x m == Instances x Attributes and so on == observations x feautures,\n",
    "iris['data'][:4]    #[o]: a preview of the first 4 obserevations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have measurements from <br>\n",
    "__150__ plants _(rows)_, for <br>\n",
    "__4__ of their features. _(columns)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. How their labels `(iris.target_names)` look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels have an alias: 0, 1, 2, and are matched to the index of target_names\n",
    "# We can see this by checking out in the variable explorer if using Spyder\n",
    "iris.target_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythonic sklearn style of objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nice to meet you `X` and `y`!\n",
    "For sklearn compatibility we will assign our data and target objects to __`X,y`__ respectively\n",
    "\n",
    "# __`X`__,\n",
    "- __capital EX__, almost always hosts the data values in sklearn supervised tasks , and can be either an numpy array or matrix.\n",
    "\n",
    "# __`y`__,\n",
    "- __psi__, is usually the vector with the labels, usually as `int`, and can be either an numpy array (N,) or a lists if you're like me and love your lists:) -- and turtle speed that comes with them xD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now assign our data to __`X`__ and the labels vector to __`y`__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus check that the X.shape[0] == y.shape[0] \n",
    "## Enough with the talking, let's proceed:\n",
    "   \n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "## Check if dimensions match:\n",
    "    \n",
    "X.shape[0] == y.shape[0] # If [o]: True, proceed | every plant comes with a species label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meet the Pandas!\n",
    "\n",
    "Say hello to this cool pylib!<br>\n",
    "Pandas is a cool pylib that helps tidy up our data, from plain `numpy.ndarray` to a neat _R-like_ :P `DataFrame`.<br> \n",
    "Perfect for data cleaning, inspecting sparse matrices, manipulating rows and columns.<br>\n",
    "\n",
    "Most probably obvious, but let's point out that this will make your sklearn iters a tad slower.<br>\n",
    "So convert back to numpy arrays freely!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://bit.ly/pyndas\",  width=400, height=400 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From __`numpy.ndarray`__ into a pretty (,) tidy __`pandas.DataFrame`__: \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Cool, now we have them like so in 2 objects, __`X`__ and __`y`__, perfect for sklearn.\n",
    "\n",
    " but let's <b>*tidy*</b> the data up a little bit,<br>\n",
    " and create a <b>pandas dataframe</b>.<br> \n",
    " Maybe also add the column names, so we know what those 4 measurements for each flower are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for `sklearn` every dataset should be: N x features\n",
    "\n",
    "Let's create the `DataFrame` with the correct orientation,<br>\n",
    "- ROWS - observations\n",
    "- COLUMNS - features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy up X in a neat Dataframe called df:\n",
    "df = pd.DataFrame(data    =  X, \n",
    "                  columns = iris.feature_names)\n",
    "df.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding `rowNames` and `columnNames`:\n",
    "\n",
    "For a __`pandas.Dataframe`__ an __`index`__ is what we would call a row name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://bit.ly/pandas_DataFrame\n",
    "\n",
    "ddf =  pd.DataFrame(data    = X, \n",
    "                    index   = iris.target,              # aka ROW NAMES!\n",
    "                    columns = iris.feature_names, \n",
    "                    dtype   = None, \n",
    "                    copy    = False)\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have changed the index from __`0`__,1,2,3,4 .. to the correspondind label {0,1,2}.<br>\n",
    "But this isn't the most convenient thing to do.<br>\n",
    "It would be better if we could add an extra column, <br>to hold the labels of each observation in the same row.<br>\n",
    "We can do that by using the __`pandas.Series()`__ functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Dataset w/ Labels: \n",
    "Add an extra column with `pd.Series()` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a list with iris subspecies names:\n",
    "\n",
    "Using a the <b>y</b> vector to create a list named <b>y_labs</b>, <br>\n",
    "with __`len(y_labs) = df.shape[0]`__, <br>\n",
    "but instead of the label alias, <b>0,1,2</b> <br>\n",
    "we will have the actual names, <b>setosa, versicolor, virginica</b>\n",
    "\n",
    "Yes, this is  __`  m e m o r y  `__  abuse but chill, it's just a tutorial m8!<br>\n",
    "We will use this label list, and add it as an extra column to the __`d f`__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add a label column to `df`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over y, and replace y's 0,1,2 with iris.target_names[0] or [1] or [2] in y_labs for setose, virginica, versicolor respectively.\n",
    "y_labs = [iris.target_names[i] for i in list(y)]\n",
    "y_labs[:5], len(y_labs) == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From `list` to compatible-for-concatenation `pandas.Series`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before adding the list of a labels as a dataframe column in the dataframe,<br>\n",
    "we will convert it from __`list`__ to __`pandas.Series`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But what is that `pandas.Series` now?? Bring `help()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comment out the following in case of an emergency (not really :P)\n",
    "\n",
    "# help (pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tack always knows best: http://bit.ly/add_column_PanDataFrame \n",
    "se = pd.Series(y_labs)\n",
    "lab_df = df \n",
    "lab_df['species'] = se.values\n",
    "\n",
    "#Let's print the updated, augmented DataFrame:\n",
    "lab_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing files\n",
    "\n",
    "Unfortunately, most datasets don't come in a tidy `bunch` format. So let's practice with more realistics examples. We will  use the dataframe of the `iris` dataset we already loaded from `sklearn`, to write it in a `.csv` file. Subsequently, we will read this `.csv` file into a Pandas Dataframe as we would typically do with a file generated from our analyses. Then, we will continue exploring the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_df.head(n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lab_df)\n",
    "lab_df.to_csv(path_or_buf = \"iris.csv\", #filename, could be full path\n",
    "               sep    = \",\", \n",
    "               header = True, # write column names\n",
    "               index  = False # DO NOT write row names\n",
    "              ) \n",
    "\n",
    "# This will write a file named iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_from_csv = pd.read_csv(filepath_or_buffer=\"../data/1-eda-with-pandas/iris.csv\")\n",
    "\n",
    "# Inspect the loaded dataframe:\n",
    "iris_from_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels instead of numeric indices:\n",
    "Lose the numbered index and use labels instead.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_from_csv = iris_from_csv.set_index(iris_from_csv['species']) # this sets  the rownames\n",
    "iris_from_csv.head(n =2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `R` - like dataframe slicing in `Pandas`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbose MODE: ON,  _\".. if values in column are <b><i> <font size=\"4\", color=\"yellowgreen\">equal</font></i></b> to..\"_\n",
    "\"Give me the part of `lab_df` for which the value of the `lab_df['species']` column is equal to `'virginica'`\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbose MODE: ON\n",
    "# Give me the part of the lab_df for which the value of the lab_df 'species' column is equal to 'virginica'\n",
    "\n",
    "setosa_df = lab_df[lab_df['species'] == 'setosa']\n",
    "setosa_df.head(n = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbose MODE: ON, _\".. if values in column are NOT equal to..\"_\n",
    "\"Give me the part of `lab_df` for which the value of the `lab_df['species']` column is __NOT__ equal to `'virginica'`\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbose MODE: ON\n",
    "# Give me the part of the lab_df for which the value of the lab_df 'species' column is NOT equal to 'virginica'\n",
    "\n",
    "NOT_virginica = lab_df[lab_df['species'] != 'virginica']\n",
    "NOT_virginica.tail(n =2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How-to: Remove a `DataFrame` column \n",
    "__Found here: https://chrisalbon.com/python/pandas_dropping_column_and_rows.html__<br><br>\n",
    "Now if you want to plot the data, slicing for excluding the _non_-numeric __`['species']`__ column, might be a hustle.\n",
    "\n",
    "So we will __`drop`__ that one for now!<BR>\n",
    "We will be using the __`DataFrame.drop()'`__ defining as arguments:<br> \n",
    "- the name of the column to delete, e.g. __`['species']`__ \n",
    "- and the __`axis=1`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://chrisalbon.com/python/pandas_dropping_column_and_rows.html\n",
    "\n",
    "NOT_virginica = NOT_virginica.drop(['species'], axis = 1)\n",
    "NOT_virginica.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Too many variables already! o_O\n",
    "\n",
    "Ok, at some point, we will need to take a look out at all the variables that we've created along the way.<br>\n",
    "__`Spyder`__ has a neat interactive __variable explorer__, but _not_ the __dashboard-y__ style,<br> \n",
    "which we very much enjoy in __Jupyter Notebooks__.<br>\n",
    "\n",
    "So, we have to somehow find a __magic!__ trick to substitute for its functionality,<br> \n",
    "while working over here in __.ipynb__ mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magic! in `Jupy Notebook`: Variable Explorer _(kind of)_\n",
    "\n",
    "Up until now we have created several variables, objects, containers `#younameit` that hold our data, metadata etc<br>\n",
    "Aah, __`Spyder`__ 's variable explorer __O_o__, where are you..\n",
    "\n",
    "Eh! There you are! <br>\n",
    "http://bit.ly/stack_variable_xplrer_jupy <br>\n",
    "or if you don't mind the lack of interactivity, try the following (hint: __` whos `__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Numerical EDA\n",
    "\n",
    "Perfect! <br>\n",
    "From __`Bunch`__ to a tidy __`DataFrame`__; success! <br>\n",
    "We learned a lot about the `pandas.Dataframe` as well.\n",
    "\n",
    "Now, let's get back to the actual content of our data and get to know them a little better;<br>\n",
    "- <b> df.head()</b>, a glimpse of how the first rows of the DataFrame looks like  \n",
    "- <b> df.describe()</b>, some descriptive summary stats\n",
    "- <b> df.info() </b>,    a look into our N x m, dimension, #instances etc \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's print the first few rows to check out how the dataframe looks like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"species\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's print some info about the dataset, eg:\n",
    "\n",
    "- Number of instances <br>\n",
    "- Type of objects <br>\n",
    "- Memory usage \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:][:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# None NaNs or NAs!\n",
    "### Quality control: Checkpoint 0\n",
    "\n",
    "Check for missing or NaN values in your `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not fully happy with this yet:\n",
    "df.isnull().head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.notnull().head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A better hack to check for null cells: \n",
    "\n",
    "Found here: https://stackoverflow.com/questions/42921854/how-to-check-if-a-particular-cell-in-pandas-dataframe-isnull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/42921854/how-to-check-if-a-particular-cell-in-pandas-dataframe-isnull\n",
    "df.isnull().any().any(),   # Q: \"Is there any empty cell in the DataFrame?\"\n",
    "df.isnull().values.any(),  # Q: \"Is there any missing value?\"                # FASTEEER! use %timeit and see 4yourself\n",
    "df.isnull().values.sum(),  # Q: \"How many missing valuess are ther?\"\n",
    "df.isnull().sum().sum()    # Q: \"Count the total number of empty cells.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, no missing values, as expected for  <b> <font size=\"6\", color=\"BA55D3\">iris</font></b> ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now check out some summary stats about the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual EDA:\n",
    "<br>\n",
    "<img src=\"https://i.imgflip.com/1w14pk.jpg\" style=\"width: 50%; height: 50%\" title=\"made at imgflip.com\"/>\n",
    "\n",
    "<br>Numerical EDA is necessary, but not very intuitive.<br>\n",
    "Let's __plot__ the data and explore a little more.<br><br>\n",
    "\n",
    "We will be using a rather cool #DataViz library, mostly used for statistics related plots, named __\"`seaborn`\"__.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quirky sns syntax found here: \n",
    "http://bit.ly/sns_quirky_syntax\n",
    "\n",
    "### Plots for EDA:\n",
    "http://bit.ly/kaggle_eda_dotpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting let's take a quick look at the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a. Scatter plot\n",
    "__`sns.FacetGrid`__ Documentation: http://bit.ly/sns_FacetGrid\n",
    "\n",
    "Correlation between two features, here: `sepal length` ~ `sepal width`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quirky sns syntax found here: http://bit.ly/sns_quirky_syntax\n",
    "\n",
    "# We'll use seaborn's FacetGrid to color the scatterplot by species\n",
    "\n",
    "# Be prepared - this one's slow.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.FacetGrid(data          = df, \n",
    "              hue           = 'species', \n",
    "              height          = 6, \n",
    "              aspect        = 1.15, \n",
    "              palette       = my_palette, \n",
    "              legend_out    = True, \n",
    "              despine       = True, \n",
    "              margin_titles = True)\\\n",
    "    .map(plt.scatter, \"sepal length (cm)\", \"sepal width (cm)\")\\\n",
    "    .add_legend()\\\n",
    "#    .fig.suptitle('seaborn FacetGrid scatter plot for iris dataset', )\n",
    "plt.title('Correlation of sepal width to sepal length by species', fontsize = 14)\n",
    "plt.savefig('scatterplot_FacetGrid_iris', \n",
    "            dpi = 300, format = 'png', pad_inches=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b. Boxplots\n",
    "Seaborn Documentation: http://bit.ly/sns_boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • `sns.boxplot()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can look at an individual feature in Seaborn through a boxplot\n",
    "\n",
    "sns.boxplot(data        = df,\n",
    "            x           = 'species', \n",
    "            y           = 'petal length (cm)',\n",
    "            hue         = 'species', \n",
    "            palette     = my_palette,\n",
    "            saturation  = 0.75, \n",
    "            width       = 0.8, \n",
    "            fliersize   = 4, \n",
    "            linewidth   = 1.2, # how thick the box outline is\n",
    "            whis        = 1.5, # 1,5 IQR past the low and high quartiles to extend the plot whiskers. Points outside this range will be identified as outliers.            \n",
    "            notch       = False)\n",
    "\n",
    "plt.title('boxplot for iris dataset (petal length)', fontsize = 16)\n",
    "plt.savefig('boxplot_iris', dpi = 300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# • `sns.boxplot()` + `sns.stripplot` hybrid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way we can extend this plot is adding a layer of individual points on top of\n",
    "# it through Seaborn's striplot\n",
    "# \n",
    "# We'll use jitter=True so that all the points don't fall in single vertical lines\n",
    "# above the species\n",
    "#\n",
    "# Saving the resulting axes as ax each time causes the resulting plot to be shown\n",
    "# on top of the previous axes\n",
    "\n",
    "\n",
    "\n",
    "ax = sns.boxplot(data        = df,\n",
    "                 x           = 'species', \n",
    "                 y           = 'petal length (cm)',\n",
    "                 hue         = 'species', \n",
    "                 palette     = my_palette,\n",
    "                 saturation  = 0.75, \n",
    "                 width       = .65, # width of boxes or if lazy, margin L and R from boxes\n",
    "                 fliersize   = 7,   # outlier symbol size | because 7 == o ari8mos tou psefti! \n",
    "                 linewidth   = 1.2, \n",
    "                 whis        = 1.5, # 1,5 IQR past the low and high quartiles to extend the plot whiskers. Points outside this range will be identified as outliers.            \n",
    "                 notch       = False)\n",
    "\n",
    "ax = sns.stripplot(data      = df,\n",
    "                   x         = 'species',\n",
    "                   y         = 'petal length (cm)', \n",
    "                   jitter    = True,\n",
    "                   linewidth = 0.2,\n",
    "                   palette   = my_palette,\n",
    "                   size      = 2,\n",
    "                   edgecolor = 'gray')\n",
    "\n",
    "#fig = plt.figure()\n",
    "#fig.set_size_inches(11.7, 8.27)\n",
    "plt.title('seaborn boxplot / stripplot hybrid plot for iris dataset', fontsize = 16)\n",
    "plt.savefig('boxplot_stripplot_iris', dpi = 1200)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# • `sns.boxplot()` + `sns.swarmplot` hybrid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way we can extend this plot is adding a layer of individual points on top of\n",
    "# it through Seaborn's striplot\n",
    "# \n",
    "# We'll use jitter=True so that all the points don't fall in single vertical lines\n",
    "# above the species\n",
    "#\n",
    "# Saving the resulting axes as ax each time causes the resulting plot to be shown\n",
    "# on top of the previous axes\n",
    "\n",
    "\n",
    "\n",
    "ax = sns.boxplot(data        = df,\n",
    "                 x           = 'species', \n",
    "                 y           = 'petal length (cm)',\n",
    "                 hue         = 'species', \n",
    "                 palette     = my_palette,\n",
    "                 saturation  = 0.75, \n",
    "                 width       = 0.765, \n",
    "                 fliersize   = 6, \n",
    "                 linewidth   = 1.2, \n",
    "                 whis        =  np.inf, # 1,5 IQR past the low and high quartiles to extend the plot whiskers. Points outside this range will be identified as outliers.            \n",
    "                 notch       = False)\n",
    "\n",
    "ax = sns.swarmplot(data      = df,\n",
    "                   x         = 'species',\n",
    "                   y         = 'petal length (cm)',\n",
    "                   palette   = my_palette,\n",
    "                   size      = 2.5,\n",
    "                   dodge = True)\n",
    "\n",
    "plt.title('seaborn boxplot/swarmplot for iris dataset (petal length)', fontsize = 10)\n",
    "plt.savefig('boxplot_swarmplot_iris', dpi = 300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way we can extend this plot is by adding a layer of individual points on top of\n",
    "# it through Seaborn's striplot\n",
    "# \n",
    "# We'll use jitter=True so that all the points don't fall in single vertical lines\n",
    "# above the species\n",
    "#\n",
    "# Saving the resulting axes as ax each time causes the resulting plot to be shown\n",
    "# on top of the previous axes\n",
    "\n",
    "\n",
    "\n",
    "ax = sns.boxenplot(data        = df,\n",
    "                x           = 'species',\n",
    "                y           = 'petal length (cm)',\n",
    "                hue         = 'species', \n",
    "                palette     = my_palette,\n",
    "                saturation  = 0.75, \n",
    "                width       = 0.765, \n",
    "                k_depth='proportion', \n",
    "                scale='exponential',\n",
    "                linewidth=None, \n",
    "                outlier_prop=None)\n",
    "\n",
    "\n",
    "\n",
    "ax = sns.swarmplot(data      = df,\n",
    "                   x         = 'species',\n",
    "                   y         = 'petal length (cm)',\n",
    "                   palette   = my_palette,\n",
    "                   size      = 2.5, \n",
    "                   dodge = True)\n",
    "\n",
    "plt.title('seaborn lvplot/swarmplot for iris dataset (petal length)', fontsize = 10)\n",
    "plt.savefig('boxplot_swarmplot_iris', dpi = 300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a detailed help message about the functions, you can call the help() method as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#help(sns.swarmplot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c. Violin Plots\n",
    "\n",
    "\n",
    "A violin plot combines the benefits of the previous two plots and simplifies them <br>\n",
    "Denser regions of the data are fatter, and sparser thiner in a violin plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.violinplot(data        = df,\n",
    "               x           = 'species', \n",
    "               y           = 'petal length (cm)',\n",
    "               hue         = 'species', \n",
    "               palette     = my_palette,\n",
    "               saturation  = 0.75, \n",
    "               width       = 0.8,\n",
    "               fliersize   = 6, \n",
    "               linewidth   = 1.2, # how thick the box outline is\n",
    "               whis        = 1.5, # 1,5 IQR past the low and high quartiles to extend the plot whiskers. Points outside this range will be identified as outliers.            \n",
    "               notch       = False)\n",
    "\n",
    "    \n",
    "# For exact placing, the title can be added as text:\n",
    "plt.text(0.5,\n",
    "         0.5,\n",
    "         horizontalalignment = 'center',\n",
    "         fontsize  = 10, \n",
    "         s = 5 ) \n",
    "         #transform = ax2.transAxes)\n",
    "\n",
    "plt.title('seaborn violin plot for iris dataset (petal length)', fontsize = 10)\n",
    "plt.savefig('violin_iris', dpi = 1200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.pairplot(data      = df, \n",
    "             hue       = 'species', \n",
    "             palette   = my_palette, \n",
    "             kind      = 'scatter', \n",
    "             diag_kind = 'kde', # kde\n",
    "             markers   = None, \n",
    "             height    = 4, \n",
    "             aspect    = 1.6 )\\\n",
    "    .fig.suptitle('seaborn pairplot for iris dataset', \n",
    "                  fontsize = 18, \n",
    "                  horizontalalignment = 'center', \n",
    "                  verticalalignment = 'top',\n",
    "                  y = 1.02)    #adjust title position # https://stackoverflow.com/questions/12750355/python-matplotlib-figure-title-overlaps-axes-label-when-using-twiny\n",
    "\n",
    "    \n",
    "# For exact placing, the title can be added as text:\n",
    "##plt.text(0.5, 1.08, figure_title,\n",
    "##        horizontalalignment='center',\n",
    "##         fontsize=20,\n",
    "##        transform = ax2.transAxes)\n",
    "plt.savefig('sns_pairplot_iris', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly_express==0.4.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Use directly Columns as argument. You can use tab completion for this!\n",
    "fig = px.scatter(iris, x=iris.sepal_length, y=iris.sepal_width, color=iris.species, size=iris.petal_length)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
